name: Build and Release Talos Unified Images

on:
  push:
    # branches:
    #   - 'renovate/siderolabs-talos-*'

jobs:
  build-and-release:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    env:
      TALOS_VERSION: v1.12.0
    steps:
      - name: Checkout repository
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1

      - name: Set up build tools
        run: |
          sudo apt-get update
          sudo apt-get install -y zstd qemu-utils tar gzip curl gnupg jq

      - name: Build unified images
        run: |
          chmod +x scripts/build-image.sh
          echo "Building amd64 image..."
          ./scripts/build-image.sh "${TALOS_VERSION}" amd64
          echo "Building arm64 image..."
          ./scripts/build-image.sh "${TALOS_VERSION}" arm64

      - name: Verify artifacts
        run: |
          # Verify metadata files
          if [ ! -f "incus-amd64.tar.xz" ]; then
            echo "Error: incus-amd64.tar.xz not found"
            exit 1
          fi
          if [ ! -f "incus-arm64.tar.xz" ]; then
            echo "Error: incus-arm64.tar.xz not found"
            exit 1
          fi
          # Verify disk files
          if [ ! -f "disk-amd64.qcow2" ]; then
            echo "Error: disk-amd64.qcow2 not found"
            exit 1
          fi
          if [ ! -f "disk-arm64.qcow2" ]; then
            echo "Error: disk-arm64.qcow2 not found"
            exit 1
          fi
          echo "✓ All artifacts verified:"
          ls -lh incus-*.tar.xz disk-*.qcow2

      - name: Calculate SHA256 hashes and sizes
        id: hashes
        run: |
          # Calculate hashes for metadata files
          AMD64_META_HASH=$(sha256sum incus-amd64.tar.xz | cut -d' ' -f1)
          ARM64_META_HASH=$(sha256sum incus-arm64.tar.xz | cut -d' ' -f1)
          AMD64_META_SIZE=$(stat -c%s incus-amd64.tar.xz)
          ARM64_META_SIZE=$(stat -c%s incus-arm64.tar.xz)
          
          # Calculate hashes for disk files
          AMD64_DISK_HASH=$(sha256sum disk-amd64.qcow2 | cut -d' ' -f1)
          ARM64_DISK_HASH=$(sha256sum disk-arm64.qcow2 | cut -d' ' -f1)
          AMD64_DISK_SIZE=$(stat -c%s disk-amd64.qcow2)
          ARM64_DISK_SIZE=$(stat -c%s disk-arm64.qcow2)
          
          # Calculate combined hash (for fingerprint) - concatenate metadata + disk, then hash
          # This matches how Incus calculates fingerprints for split images
          cat incus-amd64.tar.xz disk-amd64.qcow2 | sha256sum | cut -d' ' -f1 > /tmp/amd64_combined_hash
          cat incus-arm64.tar.xz disk-arm64.qcow2 | sha256sum | cut -d' ' -f1 > /tmp/arm64_combined_hash
          AMD64_COMBINED_HASH=$(cat /tmp/amd64_combined_hash)
          ARM64_COMBINED_HASH=$(cat /tmp/arm64_combined_hash)
          
          CREATION_DATE=$(date +%s)
          
          # Output all hashes and sizes
          echo "amd64_meta_hash=${AMD64_META_HASH}" >> $GITHUB_OUTPUT
          echo "arm64_meta_hash=${ARM64_META_HASH}" >> $GITHUB_OUTPUT
          echo "amd64_disk_hash=${AMD64_DISK_HASH}" >> $GITHUB_OUTPUT
          echo "arm64_disk_hash=${ARM64_DISK_HASH}" >> $GITHUB_OUTPUT
          echo "amd64_combined_hash=${AMD64_COMBINED_HASH}" >> $GITHUB_OUTPUT
          echo "arm64_combined_hash=${ARM64_COMBINED_HASH}" >> $GITHUB_OUTPUT
          echo "amd64_meta_size=${AMD64_META_SIZE}" >> $GITHUB_OUTPUT
          echo "arm64_meta_size=${ARM64_META_SIZE}" >> $GITHUB_OUTPUT
          echo "amd64_disk_size=${AMD64_DISK_SIZE}" >> $GITHUB_OUTPUT
          echo "arm64_disk_size=${ARM64_DISK_SIZE}" >> $GITHUB_OUTPUT
          echo "creation_date=${CREATION_DATE}" >> $GITHUB_OUTPUT
          
          echo "✓ Hashes and sizes calculated:"
          echo "  AMD64 Metadata: ${AMD64_META_HASH} (${AMD64_META_SIZE} bytes)"
          echo "  AMD64 Disk: ${AMD64_DISK_HASH} (${AMD64_DISK_SIZE} bytes)"
          echo "  AMD64 Combined: ${AMD64_COMBINED_HASH}"
          echo "  ARM64 Metadata: ${ARM64_META_HASH} (${ARM64_META_SIZE} bytes)"
          echo "  ARM64 Disk: ${ARM64_DISK_HASH} (${ARM64_DISK_SIZE} bytes)"
          echo "  ARM64 Combined: ${ARM64_COMBINED_HASH}"
      
      - name: Verify artifacts exist and match hashes
        run: |
          # Recalculate hashes from files to verify they match
          AMD64_META_VERIFY=$(sha256sum incus-amd64.tar.xz | cut -d' ' -f1)
          ARM64_META_VERIFY=$(sha256sum incus-arm64.tar.xz | cut -d' ' -f1)
          AMD64_DISK_VERIFY=$(sha256sum disk-amd64.qcow2 | cut -d' ' -f1)
          ARM64_DISK_VERIFY=$(sha256sum disk-arm64.qcow2 | cut -d' ' -f1)
          
          if [ "${AMD64_META_VERIFY}" != "${{ steps.hashes.outputs.amd64_meta_hash }}" ]; then
            echo "Error: AMD64 metadata hash mismatch!"
            exit 1
          fi
          
          if [ "${ARM64_META_VERIFY}" != "${{ steps.hashes.outputs.arm64_meta_hash }}" ]; then
            echo "Error: ARM64 metadata hash mismatch!"
            exit 1
          fi
          
          if [ "${AMD64_DISK_VERIFY}" != "${{ steps.hashes.outputs.amd64_disk_hash }}" ]; then
            echo "Error: AMD64 disk hash mismatch!"
            exit 1
          fi
          
          if [ "${ARM64_DISK_VERIFY}" != "${{ steps.hashes.outputs.arm64_disk_hash }}" ]; then
            echo "Error: ARM64 disk hash mismatch!"
            exit 1
          fi
          
          echo "✓ Hash verification passed for all files"

      - name: Import GPG key
        run: |
          echo "${{ secrets.GPG_PRIVATE_KEY }}" | base64 -d | gpg --batch --import
          gpg --list-secret-keys --keyid-format LONG
        env:
          GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE }}

      - name: Sign artifacts
        run: |
          GPG_KEY_ID=$(gpg --list-secret-keys --keyid-format LONG | grep '^sec' | awk '{print $2}' | cut -d'/' -f2 | head -1)
          echo "Signing with key: ${GPG_KEY_ID}"
          # Sign metadata files
          gpg --batch --yes --detach-sign --armor \
            --pinentry-mode loopback \
            --passphrase "${{ secrets.GPG_PASSPHRASE }}" \
            -u "${GPG_KEY_ID}" \
            -o incus-amd64.tar.xz.asc \
            incus-amd64.tar.xz
          gpg --batch --yes --detach-sign --armor \
            --pinentry-mode loopback \
            --passphrase "${{ secrets.GPG_PASSPHRASE }}" \
            -u "${GPG_KEY_ID}" \
            -o incus-arm64.tar.xz.asc \
            incus-arm64.tar.xz
          # Sign disk files
          gpg --batch --yes --detach-sign --armor \
            --pinentry-mode loopback \
            --passphrase "${{ secrets.GPG_PASSPHRASE }}" \
            -u "${GPG_KEY_ID}" \
            -o disk-amd64.qcow2.asc \
            disk-amd64.qcow2
          gpg --batch --yes --detach-sign --armor \
            --pinentry-mode loopback \
            --passphrase "${{ secrets.GPG_PASSPHRASE }}" \
            -u "${GPG_KEY_ID}" \
            -o disk-arm64.qcow2.asc \
            disk-arm64.qcow2
          echo "✓ Signatures created:"
          ls -lh *.asc
        env:
          GPG_PASSPHRASE: ${{ secrets.GPG_PASSPHRASE }}

      - name: Look up KV namespace ID by name
        id: kv_namespace
        run: |
          # Look up namespace by name (same as deploy workflow)
          NAMESPACE_NAME="windsorcli-dev-images"
          NAMESPACE_ID=$(curl -s -X GET "https://api.cloudflare.com/client/v4/accounts/${{ secrets.CLOUDFLARE_ACCOUNT_ID }}/storage/kv/namespaces" \
            -H "Authorization: Bearer ${{ secrets.CLOUDFLARE_API_TOKEN }}" \
            -H "Content-Type: application/json" | \
            python3 -c "import sys, json; data=json.load(sys.stdin); ns=[n for n in data.get('result', []) if n.get('title') == '$NAMESPACE_NAME']; print(ns[0]['id'] if ns else '')" || echo "")
          
          if [ -z "$NAMESPACE_ID" ]; then
            echo "Error: KV namespace '$NAMESPACE_NAME' not found"
            echo "Please ensure the namespace exists in Cloudflare Dashboard"
            exit 1
          fi
          
          echo "namespace_id=$NAMESPACE_ID" >> $GITHUB_OUTPUT
          echo "✓ Found KV namespace '$NAMESPACE_NAME' with ID: $NAMESPACE_ID"

      - name: Upload metadata to Cloudflare KV
        run: |
          # Upload metadata to KV store for simplestream support
          # Key format: product:talos:{version}:{arch}:{variant}
          # Value: JSON with hash, size, creation_date
          # Also maintain products:list -> array of product keys (lightweight, just strings)
          REPO="talos-incus"
          
          # Trim whitespace and verify hash format (64 hex chars)
          AMD64_META_HASH=$(echo "${{ steps.hashes.outputs.amd64_meta_hash }}" | tr -d '[:space:]')
          ARM64_META_HASH=$(echo "${{ steps.hashes.outputs.arm64_meta_hash }}" | tr -d '[:space:]')
          AMD64_DISK_HASH=$(echo "${{ steps.hashes.outputs.amd64_disk_hash }}" | tr -d '[:space:]')
          ARM64_DISK_HASH=$(echo "${{ steps.hashes.outputs.arm64_disk_hash }}" | tr -d '[:space:]')
          AMD64_COMBINED_HASH=$(echo "${{ steps.hashes.outputs.amd64_combined_hash }}" | tr -d '[:space:]')
          ARM64_COMBINED_HASH=$(echo "${{ steps.hashes.outputs.arm64_combined_hash }}" | tr -d '[:space:]')
          
          AMD64_META_SIZE="${{ steps.hashes.outputs.amd64_meta_size }}"
          ARM64_META_SIZE="${{ steps.hashes.outputs.arm64_meta_size }}"
          AMD64_DISK_SIZE="${{ steps.hashes.outputs.amd64_disk_size }}"
          ARM64_DISK_SIZE="${{ steps.hashes.outputs.arm64_disk_size }}"
          CREATION_DATE="${{ steps.hashes.outputs.creation_date }}"
          
          # Verify hash lengths
          if [ ${#AMD64_META_HASH} -ne 64 ] || [ ${#ARM64_META_HASH} -ne 64 ] || \
             [ ${#AMD64_DISK_HASH} -ne 64 ] || [ ${#ARM64_DISK_HASH} -ne 64 ] || \
             [ ${#AMD64_COMBINED_HASH} -ne 64 ] || [ ${#ARM64_COMBINED_HASH} -ne 64 ]; then
            echo "Error: Invalid hash length (expected 64 hex characters)"
            exit 1
          fi
          
          # Product keys (consistent format for all entries)
          PRODUCT_AMD64="product:talos:${TALOS_VERSION}:amd64:default"
          PRODUCT_ARM64="product:talos:${TALOS_VERSION}:arm64:default"
          
          # Create metadata JSON for each architecture (split format)
          # Stores both metadata and disk file info, plus combined hash for fingerprint
          AMD64_METADATA=$(jq -n \
            --arg meta_hash "${AMD64_META_HASH}" \
            --arg disk_hash "${AMD64_DISK_HASH}" \
            --arg combined_hash "${AMD64_COMBINED_HASH}" \
            --arg meta_size "${AMD64_META_SIZE}" \
            --arg disk_size "${AMD64_DISK_SIZE}" \
            --arg date "${CREATION_DATE}" \
            '{
              meta_hash: $meta_hash,
              meta_size: ($meta_size | tonumber),
              disk_hash: $disk_hash,
              disk_size: ($disk_size | tonumber),
              combined_hash: $combined_hash,
              creation_date: ($date | tonumber)
            }')
          
          ARM64_METADATA=$(jq -n \
            --arg meta_hash "${ARM64_META_HASH}" \
            --arg disk_hash "${ARM64_DISK_HASH}" \
            --arg combined_hash "${ARM64_COMBINED_HASH}" \
            --arg meta_size "${ARM64_META_SIZE}" \
            --arg disk_size "${ARM64_DISK_SIZE}" \
            --arg date "${CREATION_DATE}" \
            '{
              meta_hash: $meta_hash,
              meta_size: ($meta_size | tonumber),
              disk_hash: $disk_hash,
              disk_size: ($disk_size | tonumber),
              combined_hash: $combined_hash,
              creation_date: ($date | tonumber)
            }')
          
          echo "Uploading metadata to KV:"
          echo "  AMD64 Metadata: ${AMD64_META_HASH} (${AMD64_META_SIZE} bytes)"
          echo "  AMD64 Disk: ${AMD64_DISK_HASH} (${AMD64_DISK_SIZE} bytes)"
          echo "  AMD64 Combined: ${AMD64_COMBINED_HASH}"
          echo "  ARM64 Metadata: ${ARM64_META_HASH} (${ARM64_META_SIZE} bytes)"
          echo "  ARM64 Disk: ${ARM64_DISK_HASH} (${ARM64_DISK_SIZE} bytes)"
          echo "  ARM64 Combined: ${ARM64_COMBINED_HASH}"
          
          NAMESPACE_ID="${{ steps.kv_namespace.outputs.namespace_id }}"
          API_TOKEN="${{ secrets.CLOUDFLARE_API_TOKEN }}"
          ACCOUNT_ID="${{ secrets.CLOUDFLARE_ACCOUNT_ID }}"
          
          # Upload product metadata (unified format - replaces old backward-compatible entries)
          curl -X PUT "https://api.cloudflare.com/client/v4/accounts/${ACCOUNT_ID}/storage/kv/namespaces/${NAMESPACE_ID}/values/${PRODUCT_AMD64}" \
            -H "Authorization: Bearer ${API_TOKEN}" \
            -H "Content-Type: application/json" \
            --data "${AMD64_METADATA}"
          
          curl -X PUT "https://api.cloudflare.com/client/v4/accounts/${ACCOUNT_ID}/storage/kv/namespaces/${NAMESPACE_ID}/values/${PRODUCT_ARM64}" \
            -H "Authorization: Bearer ${API_TOKEN}" \
            -H "Content-Type: application/json" \
            --data "${ARM64_METADATA}"
          
          # Update products list (lightweight array of product keys, just strings)
          # This list is small - each entry is just a string like "product:talos:v1.12.0:amd64:default"
          set +e
          PRODUCTS_RESPONSE=$(curl -s -X GET "https://api.cloudflare.com/client/v4/accounts/${ACCOUNT_ID}/storage/kv/namespaces/${NAMESPACE_ID}/values/products:list" \
            -H "Authorization: Bearer ${API_TOKEN}" \
            -H "Content-Type: application/json" 2>&1)
          CURL_EXIT=$?
          set -e
          
          if [ ${CURL_EXIT} -ne 0 ] || [ -z "${PRODUCTS_RESPONSE}" ]; then
            PRODUCTS_RESPONSE=""
          fi
          
          # Initialize with empty array as default
          EXISTING_PRODUCTS="[]"
          
          # Check if we got a valid response
          if [ -z "${PRODUCTS_RESPONSE}" ]; then
            echo "Note: products:list key doesn't exist yet (first run), starting with empty array"
          elif ! echo "${PRODUCTS_RESPONSE}" | jq -e '.success == true' >/dev/null 2>&1; then
            echo "Warning: Failed to parse products list response, using empty array"
            echo "  Response: ${PRODUCTS_RESPONSE:0:200}..."
          else
            # Extract the result field (KV stores JSON as a string, so result is a JSON string)
            # If result is null or missing, default to empty array
            RESULT_VALUE=$(echo "${PRODUCTS_RESPONSE}" | jq -r '.result // "[]"' 2>/dev/null || echo "[]")
            
            # If result is the literal string "null", treat as empty
            if [ "${RESULT_VALUE}" = "null" ] || [ -z "${RESULT_VALUE}" ]; then
              EXISTING_PRODUCTS="[]"
            else
              EXISTING_PRODUCTS="${RESULT_VALUE}"
            fi
          fi
          
          # Validate it's a valid JSON array (always succeeds, defaults to empty array if invalid)
          if ! echo "${EXISTING_PRODUCTS}" | jq -e 'type == "array"' >/dev/null 2>&1; then
            echo "Warning: Invalid products list format, resetting to empty array"
            echo "  Received: ${EXISTING_PRODUCTS:0:100}..."
            EXISTING_PRODUCTS="[]"
          fi
          
          # Add new products if not already present (idempotent)
          # Product keys format: product:talos:{version}:{arch}:{variant}
          UPDATED_PRODUCTS=$(echo "${EXISTING_PRODUCTS}" | jq --arg p1 "${PRODUCT_AMD64}" --arg p2 "${PRODUCT_ARM64}" \
            'if index($p1) == null then . + [$p1] else . end | if index($p2) == null then . + [$p2] else . end' 2>/dev/null || echo "[]")
          
          # Validate the updated products list is valid JSON
          if ! echo "${UPDATED_PRODUCTS}" | jq -e 'type == "array"' >/dev/null 2>&1; then
            echo "Error: Failed to generate valid products list"
            echo "  EXISTING_PRODUCTS: ${EXISTING_PRODUCTS}"
            echo "  UPDATED_PRODUCTS: ${UPDATED_PRODUCTS}"
            exit 1
          fi
          
          PRODUCT_COUNT=$(echo "${UPDATED_PRODUCTS}" | jq -r '. | length' 2>/dev/null || echo "0")
          echo "Products list updated:"
          echo "  Total products: ${PRODUCT_COUNT}"
          
          # Upload the updated products list
          PUT_RESPONSE=$(curl -s -X PUT "https://api.cloudflare.com/client/v4/accounts/${ACCOUNT_ID}/storage/kv/namespaces/${NAMESPACE_ID}/values/products:list" \
            -H "Authorization: Bearer ${API_TOKEN}" \
            -H "Content-Type: application/json" \
            --data "${UPDATED_PRODUCTS}")
          
          # Verify the upload succeeded
          if ! echo "${PUT_RESPONSE}" | jq -e '.success == true' >/dev/null 2>&1; then
            echo "Error: Failed to upload products list to KV"
            echo "  Response: ${PUT_RESPONSE}"
            exit 1
          fi
          
          echo "✓ Metadata uploaded to Cloudflare KV"

      - name: Create GitHub Release
        run: |
          # Build file list for release
          RELEASE_FILES=("incus-amd64.tar.xz" "incus-arm64.tar.xz" "incus-amd64.tar.xz.asc" "incus-arm64.tar.xz.asc")
          
          NOTES="Automated release of Talos OS split-format images for Incus.
          
          **Version:** ${TALOS_VERSION}
          
          **Architectures:**
          - amd64 (x86_64)
          - arm64 (aarch64)
          
          **Usage (Simplestreams - Recommended):**
          
          \`\`\`bash
          incus remote add talos https://images.windsorcli.dev --protocol simplestreams
          incus image list talos:
          incus launch talos:talos/${TALOS_VERSION}/amd64 my-talos-instance
          \`\`\`
          
          **Verification:**
          
          Verify metadata files:
          \`\`\`bash
          gpg --verify incus-amd64.tar.xz.asc incus-amd64.tar.xz
          gpg --verify incus-arm64.tar.xz.asc incus-arm64.tar.xz
          \`\`\`
          
          Verify disk files:
          \`\`\`bash
          gpg --verify disk-amd64.qcow2.asc disk-amd64.qcow2
          gpg --verify disk-arm64.qcow2.asc disk-arm64.qcow2
          \`\`\`"
          
          gh release create "${TALOS_VERSION}" \
            --title "Talos ${TALOS_VERSION}" \
            --notes "${NOTES}" \
            --latest \
            "${RELEASE_FILES[@]}"
        env:
          GH_TOKEN: ${{ github.token }}
